<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>How Documents Met Graph Theory | Andrea Gemelli</title>
<meta name="keywords" content="DocAI, Graphs">
<meta name="description" content="An introductory blog post to GNNs and Document AI">
<meta name="author" content="Andrea Gemelli">
<link rel="canonical" href="http://localhost:1313/posts/docs_and_graphs/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.54f6d3849888d9ca90430bf3a058740e423abebb611e6332d18bf13a653ec3aa.css" integrity="sha256-VPbThJiI2cqQQwvzoFh0DkI6vrthHmMy0YvxOmU&#43;w6o=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/assets/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/assets/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/assets/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/assets/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/assets/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/docs_and_graphs/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="How Documents Met Graph Theory" />
<meta property="og:description" content="An introductory blog post to GNNs and Document AI" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/docs_and_graphs/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-22T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-03-22T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="How Documents Met Graph Theory"/>
<meta name="twitter:description" content="An introductory blog post to GNNs and Document AI"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "How Documents Met Graph Theory",
      "item": "http://localhost:1313/posts/docs_and_graphs/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "How Documents Met Graph Theory",
  "name": "How Documents Met Graph Theory",
  "description": "An introductory blog post to GNNs and Document AI",
  "keywords": [
    "DocAI", "Graphs"
  ],
  "articleBody": "How our brain processes and understands documents? It’s not just about reading words sequentially - we naturally perceive relationships between different parts of a page, like how titles relate to paragraphs or how table cells connect to form meaningful structures. This intuitive way of understanding documents through relationships creates an exciting intersection between document analysis and graph theory, which strongly inspired my PhD thesis “Connecting the DOCS: a graph-based approach to document understanding” 1.\nThis article is an introductory version of its second chapter, summarizing the key aspects and interesting spots of this niche of Document AI.\nWhat’s a Graph Anyway? First proposed by Leonhard Euler in 1736 when solving the famous Seven Bridges of Königsberg problem 2, a graph is a collection of objects (nodes) and the relationships between them (edges). This elegant mathematical concept first appeared in a Nature paper about “chemistry and algebra” 3 in 1878, but it wasn’t until 1936 that graph theory got its foundations with its first textbook 4.\nThe problem that started it all: Euler’s visualization of the Seven Bridges of Königsberg\nThe beauty of graphs lies in their natural ability to represent how we see patterns in the world. Think about it - when you look at a molecule, it’s not just a bunch of atoms but a structured arrangement of chemical bonds. Similarly, when you use Google Maps, it’s a weighted graph that find the best route for you under the hood!\nFrom Brain to Computer: The Geometric Deep Learning Revolution Our understanding of how the brain processes visual information has profoundly influenced the Machine Learning research field. The multi-layer structure of neurons in our visual cortex, with simpler cells detecting basic patterns that get combined into more complex features 5, inspired early artificial neural networks like the Neocognitron 6 in the 1980s. This eventually evolved into modern Convolutional Neural Networks (CNNs) that revolutionized computer vision 7.\nMore recently, some researchers have unified various deep learning approaches (CNNs, RNNs, Transfomers, etc.) under the framework of Geometric Deep Learning (GDL)8. This new term defines how different neural network architectures relate to each other and why they work so well for their specific domains.\nGraph Neural Networks Graph Neural Networks (GNNs) emerged in the early 2000s 9 10 as a way to apply deep learning directly to graph structures. What makes GNNs special is their ability to learn from both the features of individual nodes and the relationships between them. Think of it like learning about a person not just by their characteristics, but also by understanding their social connections. As shown in the picture, several entities can be represented using domain-dependent structures such as graphs for molecules or social networks.\nExamples of graphs representing brain connections, chemicals and social networks (img credits Bscarleth Gtz)\nRepresenting documents as graphs Documents have always been created with precise logical arrangements of objects in relation to each other 11. This inherent structure makes them perfect candidates for graph representation. The journey of using graphs for document analysis started in the 1980s with hierarchical trees for page segmentation 12, evolved through Voronoi diagrams for layout analysis 13, and has now reached sophisticated graph-based representations that can capture complex document structures.\nThe modern approach to creating a document graph representation typically follows these steps:\nDefine the nodes (these could be words, text lines, or larger document entities) Create links between nodes using rules like k-nearest neighbors or visibility graphs Add features to nodes (like position, text content, or visual characteristics) Optionally add features to edges (like distances or relative positions) How graph-like document representations evolved over time\nWhy It Matters This graph-based approach to document understanding has several key advantages:\nStructure matters: Graphs can capture the spatial and logical relationships that are crucial for understanding documents Efficiency: Graph-based methods often require fewer parameters than other deep learning approaches while maintaining good performance Versatility: A single graph representation can be used to solve multiple document understanding tasks Doc2Graph to the rescue Building on these ideas, I developed Doc2Graph 14, an open-source framework that puts these concepts into practice. Doc2Graph provides a task-agnostic approach to document understanding, allowing researchers and developers to represent any document as a graph structure. The framework is designed to be lightweight yet effective, handling multiple document understanding tasks with significantly fewer parameters than traditional approaches.\nWant to try it yourself? Check out the tutorial section of the Doc2Graph repository!\nThe Road Ahead As we continue to develop better ways to make computers understand documents, graph-based approaches are showing great promise. Whether it’s extracting information from tables, understanding form layouts, or analyzing complex document structures, graphs provide a powerful and intuitive framework for tackling these challenges.\nReferences Gemelli, A. (2024). Connecting the DOCS: a graph-based approach to document understanding. PhD thesis, University of Florence. ↩︎\nEuler, L. (1741). Solutio problematis ad geometriam situs pertinentis. Commentarii academiae scientiarum Petropolitanae, 128-140. ↩︎\nSylvester, J. J. (1878). Chemistry and Algebra. Nature, 17(432), 284. ↩︎\nBiggs, N., Lloyd, E. K., \u0026 Wilson, R. J. (1986). Graph Theory, 1736-1936. Oxford University Press. ↩︎\nHubel, D. H., \u0026 Wiesel, T. N. (1959). Receptive fields of single neurones in the cat’s striate cortex. The Journal of physiology, 148(3), 574. ↩︎\nFukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological cybernetics, 36(4), 193-202. ↩︎\nLeCun, Y., Bottou, L., Bengio, Y., \u0026 Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324. ↩︎\nBronstein, M. M., Bruna, J., Cohen, T., \u0026 Veličković, P. (2021). Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. arXiv preprint arXiv:2104.13478. ↩︎\nGori, M., Monfardini, G., \u0026 Scarselli, F. (2005). A new model for learning in graph domains. Proceedings IEEE IJCNN. ↩︎\nScarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., \u0026 Monfardini, G. (2009). The graph neural network model. IEEE transactions on neural networks, 20(1), 61-80. ↩︎\nHaralick, R. M. (1994). Document image understanding: Geometric and logical layout. CVPR ‘94. ↩︎\nNagy, G., \u0026 Seth, S. (1984). Hierarchical representation of optically scanned documents. ICPR. ↩︎\nKise, K., Sato, A., \u0026 Iwata, M. (1998). Segmentation of page images using the area Voronoi diagram. Computer Vision and Image Understanding. ↩︎\nGemelli, A., Biswas, S., Civitelli, E., Lladós, J., \u0026 Marinai, S. (2022). Doc2Graph: A Task Agnostic Document Understanding Framework Based on Graph Neural Networks. In Computer Vision – ECCV 2022 Workshops (pp. 329-344). ↩︎\n",
  "wordCount" : "1056",
  "inLanguage": "en",
  "datePublished": "2024-03-22T00:00:00Z",
  "dateModified": "2024-03-22T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Andrea Gemelli"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/docs_and_graphs/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Andrea Gemelli",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/assets/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Andrea Gemelli (Alt + H)">Andrea Gemelli</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/about" title="About me">
                    <span>About me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/publications" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="AI Notes">
                    <span>AI Notes</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      How Documents Met Graph Theory
    </h1>
    <div class="post-description">
      An introductory blog post to GNNs and Document AI
    </div>
    <div class="post-meta"><span title='2024-03-22 00:00:00 +0000 UTC'>March 22, 2024</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Andrea Gemelli

</div>
  </header> 
  <div class="post-content"><p>How our brain processes and understands documents? It&rsquo;s not just about reading words sequentially - we naturally perceive relationships between different parts of a page, like how titles relate to paragraphs or how table cells connect to form meaningful structures. This intuitive way of understanding documents through relationships creates an exciting intersection between document analysis and graph theory, which strongly inspired my PhD thesis &ldquo;Connecting the DOCS: a graph-based approach to document understanding&rdquo; <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>This article is an introductory version of its second chapter, summarizing the key aspects and interesting spots of this niche of Document AI.</p>
<h2 id="whats-a-graph-anyway">What&rsquo;s a Graph Anyway?<a hidden class="anchor" aria-hidden="true" href="#whats-a-graph-anyway">#</a></h2>
<p>First proposed by Leonhard Euler in 1736 when solving the famous Seven Bridges of Königsberg problem <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, a graph is a collection of objects (nodes) and the relationships between them (edges). This elegant mathematical concept first appeared in a Nature paper about &ldquo;chemistry and algebra&rdquo; <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> in 1878, but it wasn&rsquo;t until 1936 that graph theory got its foundations with its first textbook <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p><img loading="lazy" src="https://kidscodecs.com/wp-content/uploads/2013/11/puzzles-7-bridges-map-euler.jpg" alt="Examples of graphs"  />

<em>The problem that started it all: Euler&rsquo;s visualization of the Seven Bridges of Königsberg</em></p>
<p>The beauty of graphs lies in their natural ability to represent how we see patterns in the world. Think about it - when you look at a molecule, it&rsquo;s not just a bunch of atoms but a structured arrangement of chemical bonds. Similarly, when you use Google Maps, it&rsquo;s a weighted graph that find the best route for you under the hood!</p>
<h2 id="from-brain-to-computer-the-geometric-deep-learning-revolution">From Brain to Computer: The Geometric Deep Learning Revolution<a hidden class="anchor" aria-hidden="true" href="#from-brain-to-computer-the-geometric-deep-learning-revolution">#</a></h2>
<p>Our understanding of how the brain processes visual information has profoundly influenced the Machine Learning research field. The multi-layer structure of neurons in our visual cortex, with simpler cells detecting basic patterns that get combined into more complex features <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, inspired early artificial neural networks like the Neocognitron <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> in the 1980s. This eventually evolved into modern Convolutional Neural Networks (CNNs) that revolutionized computer vision <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>More recently, some researchers have unified various deep learning approaches (CNNs, RNNs, Transfomers, etc.) under the framework of Geometric Deep Learning (GDL)<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. This new term defines how different neural network architectures relate to each other and why they work so well for their specific domains.</p>
<h3 id="graph-neural-networks">Graph Neural Networks<a hidden class="anchor" aria-hidden="true" href="#graph-neural-networks">#</a></h3>
<p>Graph Neural Networks (GNNs) emerged in the early 2000s <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> as a way to apply deep learning directly to graph structures. What makes GNNs special is their ability to learn from both the features of individual nodes and the relationships between them. Think of it like learning about a person not just by their characteristics, but also by understanding their social connections. As shown in the picture, several entities can be represented using domain-dependent structures such as graphs for molecules or social networks.</p>
<p><img loading="lazy" src="https://miro.medium.com/v2/resize:fit:1029/1*txzoFgR0XvAy4PpIgbUyvQ.png" alt="Graphs representation of different entities"  />

<em>Examples of graphs representing brain connections, chemicals and social networks (img credits <a href="https://medium.com/@bscarleth.gtz/introduction-to-graph-neural-networks-an-illustrated-guide-c3f19da2ba39">Bscarleth Gtz</a>)</em></p>
<h2 id="representing-documents-as-graphs">Representing documents as graphs<a hidden class="anchor" aria-hidden="true" href="#representing-documents-as-graphs">#</a></h2>
<p>Documents have always been created with precise logical arrangements of objects in relation to each other <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. This inherent structure makes them perfect candidates for graph representation. The journey of using graphs for document analysis started in the 1980s with hierarchical trees for page segmentation <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>, evolved through Voronoi diagrams for layout analysis <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>, and has now reached sophisticated graph-based representations that can capture complex document structures.</p>
<p>The modern approach to creating a document graph representation typically follows these steps:</p>
<ol>
<li>Define the nodes (these could be words, text lines, or larger document entities)</li>
<li>Create links between nodes using rules like k-nearest neighbors or visibility graphs</li>
<li>Add features to nodes (like position, text content, or visual characteristics)</li>
<li>Optionally add features to edges (like distances or relative positions)</li>
</ol>
<p><img loading="lazy" src="images/timeline.jpg" alt="Evolution of document graph representations"  />

<em>How graph-like document representations evolved over time</em></p>
<h3 id="why-it-matters">Why It Matters<a hidden class="anchor" aria-hidden="true" href="#why-it-matters">#</a></h3>
<p>This graph-based approach to document understanding has several key advantages:</p>
<ul>
<li>Structure matters: Graphs can capture the spatial and logical relationships that are crucial for understanding documents</li>
<li>Efficiency: Graph-based methods often require fewer parameters than other deep learning approaches while maintaining good performance</li>
<li>Versatility: A single graph representation can be used to solve multiple document understanding tasks</li>
</ul>
<h3 id="doc2graph-to-the-rescue">Doc2Graph to the rescue<a hidden class="anchor" aria-hidden="true" href="#doc2graph-to-the-rescue">#</a></h3>
<p>Building on these ideas, I developed Doc2Graph <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, an open-source framework that puts these concepts into practice. Doc2Graph provides a task-agnostic approach to document understanding, allowing researchers and developers to represent any document as a graph structure. The framework is designed to be lightweight yet effective, handling multiple document understanding tasks with significantly fewer parameters than traditional approaches.</p>
<p>Want to try it yourself? Check out the tutorial section of the <a href="https://github.com/andreagemelli/doc2graph">Doc2Graph repository</a>!</p>
<h2 id="the-road-ahead">The Road Ahead<a hidden class="anchor" aria-hidden="true" href="#the-road-ahead">#</a></h2>
<p>As we continue to develop better ways to make computers understand documents, graph-based approaches are showing great promise. Whether it&rsquo;s extracting information from tables, understanding form layouts, or analyzing complex document structures, graphs provide a powerful and intuitive framework for tackling these challenges.</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Gemelli, A. (2024). Connecting the DOCS: a graph-based approach to document understanding. PhD thesis, University of Florence.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Euler, L. (1741). Solutio problematis ad geometriam situs pertinentis. Commentarii academiae scientiarum Petropolitanae, 128-140.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Sylvester, J. J. (1878). Chemistry and Algebra. Nature, 17(432), 284.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Biggs, N., Lloyd, E. K., &amp; Wilson, R. J. (1986). Graph Theory, 1736-1936. Oxford University Press.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Hubel, D. H., &amp; Wiesel, T. N. (1959). Receptive fields of single neurones in the cat&rsquo;s striate cortex. The Journal of physiology, 148(3), 574.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological cybernetics, 36(4), 193-202.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Bronstein, M. M., Bruna, J., Cohen, T., &amp; Veličković, P. (2021). Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. arXiv preprint arXiv:2104.13478.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Gori, M., Monfardini, G., &amp; Scarselli, F. (2005). A new model for learning in graph domains. Proceedings IEEE IJCNN.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., &amp; Monfardini, G. (2009). The graph neural network model. IEEE transactions on neural networks, 20(1), 61-80.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Haralick, R. M. (1994). Document image understanding: Geometric and logical layout. CVPR &lsquo;94.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Nagy, G., &amp; Seth, S. (1984). Hierarchical representation of optically scanned documents. ICPR.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Kise, K., Sato, A., &amp; Iwata, M. (1998). Segmentation of page images using the area Voronoi diagram. Computer Vision and Image Understanding.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Gemelli, A., Biswas, S., Civitelli, E., Lladós, J., &amp; Marinai, S. (2022). Doc2Graph: A Task Agnostic Document Understanding Framework Based on Graph Neural Networks. In Computer Vision – ECCV 2022 Workshops (pp. 329-344).&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/docai/">DocAI</a></li>
      <li><a href="http://localhost:1313/tags/graphs/">Graphs</a></li>
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How Documents Met Graph Theory on x"
            href="https://x.com/intent/tweet/?text=How%20Documents%20Met%20Graph%20Theory&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocs_and_graphs%2f&amp;hashtags=DocAI%2cGraphs">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How Documents Met Graph Theory on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocs_and_graphs%2f&amp;title=How%20Documents%20Met%20Graph%20Theory&amp;summary=How%20Documents%20Met%20Graph%20Theory&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocs_and_graphs%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Andrea Gemelli</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
