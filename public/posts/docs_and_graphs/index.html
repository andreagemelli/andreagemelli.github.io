<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>How Documents Met Graph Theory | Andrea Gemelli</title>
<meta name="keywords" content="DocAI, Graphs">
<meta name="description" content="An introductory blog post to GNNs and Document AI">
<meta name="author" content="Andrea Gemelli">
<link rel="canonical" href="http://localhost:1313/posts/docs_and_graphs/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8432b9935c337818100bd59a8f286eb085ff93e46a00b42b1cb073fa0b739933.css" integrity="sha256-hDK5k1wzeBgQC9WajyhusIX/k&#43;RqALQrHLBz&#43;gtzmTM=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/assets/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/assets/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/assets/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/assets/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/assets/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/docs_and_graphs/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="How Documents Met Graph Theory" />
<meta property="og:description" content="An introductory blog post to GNNs and Document AI" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/docs_and_graphs/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-11-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-11-11T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="How Documents Met Graph Theory"/>
<meta name="twitter:description" content="An introductory blog post to GNNs and Document AI"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "How Documents Met Graph Theory",
      "item": "http://localhost:1313/posts/docs_and_graphs/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "How Documents Met Graph Theory",
  "name": "How Documents Met Graph Theory",
  "description": "An introductory blog post to GNNs and Document AI",
  "keywords": [
    "DocAI", "Graphs"
  ],
  "articleBody": "In our daily life, we are submerged by piles of documents ü´†: burocracy, bills, insurances, etc. As humans, we invented this medium to vehicle important information! But how our brain processes documents? ü§î\nOne could think just about reading words sequentially! But we also naturally perceive relationships between different parts of a page, exploiting the layout as a semantinc meaningful piece of information! Think about titles and subtitles or pharagraph that structure a contract or about table cells whose meaning depends on the tables structure and the name of the columns!\nThis intuitive - yet effective - way of reading documents through relationships creates an exciting intersection between document analysis and graph theory üí°, which strongly inspired my PhD thesis ‚ÄúConnecting the DOCS: a graph-based approach to document understanding‚Äù 1. This article is an introductory version of its second chapter, summarizing the key aspects and interesting spots of this niche of Document AI.\nWhat is a graph anyway? First proposed by Leonhard Euler in 1736 when solving the famous Seven Bridges of K√∂nigsberg problem 2, a graph is a collection of objects (nodes) and the relationships between them (edges). This elegant mathematical concept first appeared in a Nature paper about ‚Äúchemistry and algebra‚Äù 3 in 1878, but it wasn‚Äôt until 1936 that graph theory got its foundations with its first textbook 4.\nThe problem that started it all: Euler‚Äôs visualization of the Seven Bridges of K√∂nigsberg\nThe beauty of graphs lies in their natural ability to represent how we see patterns in the world. Think about it - when you look at a molecule, it‚Äôs not just a bunch of atoms but a structured arrangement of chemical bonds. Similarly, when you use Google Maps, it‚Äôs a weighted graph that find the best route for you under the hood!\nFrom Brain to Computer Our understanding of how the brain processes visual information has profoundly influenced the Machine Learning research field. The multi-layer structure of neurons in our visual cortex, with simpler cells detecting basic patterns that get combined into more complex features 5, inspired early artificial neural networks like the Neocognitron 6 in the 1980s. This eventually evolved into modern Neural Networks - such as CNNs7 8, LSTM9, GANs10, Transformers11 - that revolutionized the machine learning fields and, whith more data and computing capabilities, started the Deep Learning era.\nGeometric Deep Learning More recently, some researchers have unified various deep learning approaches under the framework of Geometric Deep Learning 12. This new term defines how different neural network architectures relate to each other and why they work so well for their specific domains. It is within this domain that graphs met deep learning, and their application started to really shine in several fields such as chemistry13 and social networks14.\nGraph Neural Networks emerged in the early 2000s 15 16 as a way to learn directly on graph structures. What makes GNNs special is their ability to learn from both the features of individual nodes and the relationships between them. Think of it like learning about a person not just by their characteristics, but also by understanding their social connections. As shown in the picture, several entities can be represented using domain-dependent structures such as graphs for molecules or social networks.\nExamples of graphs representing brain connections, chemicals and social networks (img credits Bscarleth Gtz)\nRepresenting documents as graphs Documents have always been created with precise logical arrangements of objects in relation to each other 17. This inherent structure makes them perfect candidates for graph representation. The journey of using graphs for document analysis started in the 1980s with hierarchical trees for page segmentation 18, evolved through Voronoi diagrams for layout analysis 19, and has now reached sophisticated graph-based representations that can capture complex document structures.\nThe modern approach to create a document graph representation typically follows these steps:\nDefine the nodes (these could be words, text lines, or larger document entities) Create links between nodes using rules like k-nearest neighbors or visibility graphs Add features to nodes (like position, text content, or visual characteristics) Optionally add features to edges (like distances or relative positions) How graph-like document representations evolved over time\nThis graph-based approach to document understanding has several key advantages:\nStructure matters: Graphs can capture the spatial and logical relationships that are crucial for understanding documents Efficiency: Graph-based methods often require fewer parameters than other deep learning approaches while maintaining good performance Versatility: A single graph representation can be used to solve multiple document understanding tasks Doc2Graph to the rescue ‚öîÔ∏è Building on these ideas, I developed Doc2Graph 20, an open-source framework that puts these concepts into practice. Doc2Graph provides a task-agnostic approach to document understanding, allowing researchers and developers to represent any document as a graph structure. The framework is designed to be lightweight yet effective, handling multiple document understanding tasks with significantly fewer parameters than traditional approaches.\n‚û° Want to try it yourself? Check out the tutorial section of the Doc2Graph repository!\nWhat‚Äôs next? As we continue to develop better ways to make computers understand documents, graph-based approaches have shown great promise. Whether it‚Äôs extracting information from tables, understanding form layouts, or analyzing complex document structures, graphs provide a powerful inductive bias to tackle these challenges.\nIn the era of LLMs - and reduced pre-training and inference time and costs - can graphs and GNNs still be a valid competitor for Document AI?\nReferences Gemelli, A. (2024). Connecting the DOCS: a graph-based approach to document understanding. PhD thesis, University of Florence.¬†‚Ü©Ô∏é\nEuler, L. (1741). Solutio problematis ad geometriam situs pertinentis. Commentarii academiae scientiarum Petropolitanae, 128-140.¬†‚Ü©Ô∏é\nSylvester, J. J. (1878). Chemistry and Algebra. Nature, 17(432), 284.¬†‚Ü©Ô∏é\nBiggs, N., Lloyd, E. K., \u0026 Wilson, R. J. (1986). Graph Theory, 1736-1936. Oxford University Press.¬†‚Ü©Ô∏é\nHubel, D. H., \u0026 Wiesel, T. N. (1959). Receptive fields of single neurones in the cat‚Äôs striate cortex. The Journal of physiology, 148(3), 574.¬†‚Ü©Ô∏é\nFukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological cybernetics, 36(4), 193-202.¬†‚Ü©Ô∏é\nLeCun, Y., Bottou, L., Bengio, Y., \u0026 Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.¬†‚Ü©Ô∏é\nAlex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks - NeurIPS 2012¬†‚Ü©Ô∏é\nSepp Hochreiter; J√ºrgen Schmidhuber (1997). Long short-term memory - Neural Computation. 9 (8): 1735‚Äì1780.¬†‚Ü©Ô∏é\nIan J. Goodfellow et al. (2014), Generative Adversarial Networks¬†‚Ü©Ô∏é\nAshish Vaswani et al. (2017), Attention is all you need¬†‚Ü©Ô∏é\nBronstein, M. M., Bruna, J., Cohen, T., \u0026 Veliƒçkoviƒá, P. (2021). Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. arXiv preprint arXiv:2104.13478.¬†‚Ü©Ô∏é\nAlphaFold blog post - AlphaFold, Google DeepMind¬†‚Ü©Ô∏é\nTemporal Graphs at Twitter - Temporal Graph Networks, Bronstein and Emanuele Rossi medium post¬†‚Ü©Ô∏é\nGori, M., Monfardini, G., \u0026 Scarselli, F. (2005). A new model for learning in graph domains. Proceedings IEEE IJCNN.¬†‚Ü©Ô∏é\nScarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., \u0026 Monfardini, G. (2009). The graph neural network model. IEEE transactions on neural networks, 20(1), 61-80.¬†‚Ü©Ô∏é\nHaralick, R. M. (1994). Document image understanding: Geometric and logical layout. CVPR ‚Äò94.¬†‚Ü©Ô∏é\nNagy, G., \u0026 Seth, S. (1984). Hierarchical representation of optically scanned documents. ICPR.¬†‚Ü©Ô∏é\nKise, K., Sato, A., \u0026 Iwata, M. (1998). Segmentation of page images using the area Voronoi diagram. Computer Vision and Image Understanding.¬†‚Ü©Ô∏é\nGemelli, A., Biswas, S., Civitelli, E., Llad√≥s, J., \u0026 Marinai, S. (2022). Doc2Graph: A Task Agnostic Document Understanding Framework Based on Graph Neural Networks. In Computer Vision ‚Äì ECCV 2022 Workshops (pp. 329-344).¬†‚Ü©Ô∏é\n",
  "wordCount" : "1242",
  "inLanguage": "en",
  "datePublished": "2024-11-11T00:00:00Z",
  "dateModified": "2024-11-11T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Andrea Gemelli"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/docs_and_graphs/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Andrea Gemelli",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/assets/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Andrea Gemelli (Alt + H)">Andrea Gemelli</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/about" title="About me">
                    <span>About me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/publications" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="AI Notes">
                    <span>AI Notes</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      How Documents Met Graph Theory
    </h1>
    <div class="post-description">
      An introductory blog post to GNNs and Document AI
    </div>
    <div class="post-meta"><span title='2024-11-11 00:00:00 +0000 UTC'>November 11, 2024</span>&nbsp;¬∑&nbsp;6 min&nbsp;¬∑&nbsp;Andrea Gemelli

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#what-is-a-graph-anyway" aria-label="What is a graph anyway?">What is a graph anyway?</a></li>
                <li>
                    <a href="#from-brain-to-computer" aria-label="From Brain to Computer">From Brain to Computer</a><ul>
                        
                <li>
                    <a href="#geometric-deep-learning" aria-label="Geometric Deep Learning">Geometric Deep Learning</a></li></ul>
                </li>
                <li>
                    <a href="#representing-documents-as-graphs" aria-label="Representing documents as graphs">Representing documents as graphs</a><ul>
                        
                <li>
                    <a href="#doc2graph-to-the-rescue-" aria-label="Doc2Graph to the rescue ‚öîÔ∏è">Doc2Graph to the rescue ‚öîÔ∏è</a></li></ul>
                </li>
                <li>
                    <a href="#whats-next" aria-label="What&rsquo;s next?">What&rsquo;s next?</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>In our daily life, we are submerged by piles of documents ü´†: burocracy, bills, insurances, etc. As humans, we invented this medium to vehicle important information! But how our brain processes documents? ü§î</p>
<p>One could think just about <em>reading</em> words sequentially! But we also naturally perceive relationships between different parts of a page, <strong>exploiting the layout as a semantinc meaningful piece of information</strong>! Think about titles and subtitles or pharagraph that structure a contract or about table cells whose meaning depends on the tables structure and the name of the columns!</p>
<p>This intuitive - yet effective - way of reading documents through relationships creates an exciting intersection between document analysis and graph theory üí°, which strongly inspired my PhD thesis &ldquo;Connecting the DOCS: a graph-based approach to document understanding&rdquo; <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This article is an introductory version of its second chapter, summarizing the key aspects and interesting spots of this niche of Document AI.</p>
<h2 id="what-is-a-graph-anyway">What is a <em>graph</em> anyway?<a hidden class="anchor" aria-hidden="true" href="#what-is-a-graph-anyway">#</a></h2>
<p>First proposed by Leonhard Euler in 1736 when solving the famous Seven Bridges of K√∂nigsberg problem <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, a graph is <strong>a collection of objects (nodes) and the relationships between them (edges)</strong>. This elegant mathematical concept first appeared in a Nature paper about <em>&ldquo;chemistry and algebra&rdquo;</em> <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> in 1878, but it wasn&rsquo;t until 1936 that graph theory got its foundations with its first textbook <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p><img loading="lazy" src="https://kidscodecs.com/wp-content/uploads/2013/11/puzzles-7-bridges-map-euler.jpg" alt="Examples of graphs"  />

<em>The problem that started it all: Euler&rsquo;s visualization of the Seven Bridges of K√∂nigsberg</em></p>
<p>The beauty of graphs lies in their natural ability to represent how we see patterns in the world. Think about it - when you look at a molecule, it&rsquo;s not just a bunch of atoms but a structured arrangement of chemical bonds. Similarly, when you use Google Maps, it&rsquo;s a weighted graph that find the best route for you under the hood!</p>
<h2 id="from-brain-to-computer">From Brain to Computer<a hidden class="anchor" aria-hidden="true" href="#from-brain-to-computer">#</a></h2>
<p>Our understanding of how the brain processes visual information has profoundly influenced the Machine Learning research field. The multi-layer structure of neurons in our visual cortex, with simpler cells detecting basic patterns that get combined into more complex features <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, inspired early artificial neural networks like the Neocognitron <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> in the 1980s. This eventually evolved into modern Neural Networks - such as CNNs<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, LSTM<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>, GANs<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>, Transformers<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> - that revolutionized the machine learning fields and, whith more data and computing capabilities, started the <strong>Deep Learning</strong> era.</p>
<h3 id="geometric-deep-learning">Geometric Deep Learning<a hidden class="anchor" aria-hidden="true" href="#geometric-deep-learning">#</a></h3>
<p>More recently, some researchers have unified various deep learning approaches under the framework of <strong>Geometric Deep Learning</strong> <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. This new term defines how different neural network architectures relate to each other and why they work so well for their specific domains. It is within this domain that graphs met deep learning, and their application started to really shine in several fields such as chemistry<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> and social networks<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.</p>
<p>Graph Neural Networks emerged in the early 2000s <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> as a way to learn directly on graph structures. What makes GNNs special is their ability to learn from both the features of individual nodes and the relationships between them. Think of it like learning about a person not just by their characteristics, but also by understanding their social connections. As shown in the picture, several entities can be represented using domain-dependent structures such as graphs for molecules or social networks.</p>
<p><img loading="lazy" src="https://miro.medium.com/v2/resize:fit:1029/1*txzoFgR0XvAy4PpIgbUyvQ.png" alt="Graphs representation of different entities"  />

<em>Examples of graphs representing brain connections, chemicals and social networks (img credits <a href="https://medium.com/@bscarleth.gtz/introduction-to-graph-neural-networks-an-illustrated-guide-c3f19da2ba39">Bscarleth Gtz</a>)</em></p>
<h2 id="representing-documents-as-graphs">Representing documents as graphs<a hidden class="anchor" aria-hidden="true" href="#representing-documents-as-graphs">#</a></h2>
<p>Documents have always been created with precise logical arrangements of objects in relation to each other <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. This inherent structure makes them perfect candidates for graph representation. The journey of using graphs for document analysis started in the 1980s with hierarchical trees for page segmentation <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>, evolved through Voronoi diagrams for layout analysis <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>, and has now reached sophisticated graph-based representations that can capture complex document structures.</p>
<p>The modern approach to create a document graph representation typically follows these steps:</p>
<ol>
<li>Define the nodes (these could be words, text lines, or larger document entities)</li>
<li>Create links between nodes using rules like k-nearest neighbors or visibility graphs</li>
<li>Add features to nodes (like position, text content, or visual characteristics)</li>
<li>Optionally add features to edges (like distances or relative positions)</li>
</ol>
<p><img loading="lazy" src="images/timeline.jpg" alt="Evolution of document graph representations"  />

<em>How graph-like document representations evolved over time</em></p>
<p>This graph-based approach to document understanding has several key advantages:</p>
<ul>
<li><strong>Structure matters</strong>: Graphs can capture the spatial and logical relationships that are crucial for understanding documents</li>
<li><strong>Efficiency</strong>: Graph-based methods often require fewer parameters than other deep learning approaches while maintaining good performance</li>
<li><strong>Versatility</strong>: A single graph representation can be used to solve multiple document understanding tasks</li>
</ul>
<h3 id="doc2graph-to-the-rescue-">Doc2Graph to the rescue ‚öîÔ∏è<a hidden class="anchor" aria-hidden="true" href="#doc2graph-to-the-rescue-">#</a></h3>
<p>Building on these ideas, I developed Doc2Graph <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>, an open-source framework that puts these concepts into practice. Doc2Graph provides a task-agnostic approach to document understanding, allowing researchers and developers to represent any document as a graph structure. The framework is designed to be lightweight yet effective, handling multiple document understanding tasks with significantly fewer parameters than traditional approaches.</p>
<p>‚û° Want to try it yourself? Check out the tutorial section of the <a href="https://github.com/andreagemelli/doc2graph">Doc2Graph repository</a>!</p>
<h2 id="whats-next">What&rsquo;s next?<a hidden class="anchor" aria-hidden="true" href="#whats-next">#</a></h2>
<p>As we continue to develop better ways to make computers understand documents, graph-based approaches have shown great promise. Whether it&rsquo;s extracting information from tables, understanding form layouts, or analyzing complex document structures, graphs provide a powerful inductive bias to tackle these challenges.</p>
<p>In the era of LLMs - and reduced pre-training and inference time and costs - can graphs and GNNs still be a valid competitor for Document AI?</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Gemelli, A. (2024). Connecting the DOCS: a graph-based approach to document understanding. PhD thesis, University of Florence.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Euler, L. (1741). Solutio problematis ad geometriam situs pertinentis. Commentarii academiae scientiarum Petropolitanae, 128-140.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Sylvester, J. J. (1878). Chemistry and Algebra. Nature, 17(432), 284.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Biggs, N., Lloyd, E. K., &amp; Wilson, R. J. (1986). Graph Theory, 1736-1936. Oxford University Press.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Hubel, D. H., &amp; Wiesel, T. N. (1959). Receptive fields of single neurones in the cat&rsquo;s striate cortex. The Journal of physiology, 148(3), 574.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological cybernetics, 36(4), 193-202.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks - NeurIPS 2012&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Sepp Hochreiter; J√ºrgen Schmidhuber (1997). Long short-term memory - Neural Computation. 9 (8): 1735‚Äì1780.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Ian J. Goodfellow et al. (2014), Generative Adversarial Networks&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Ashish Vaswani et al. (2017), Attention is all you need&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Bronstein, M. M., Bruna, J., Cohen, T., &amp; Veliƒçkoviƒá, P. (2021). Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. arXiv preprint arXiv:2104.13478.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p><a href="https://deepmind.google/technologies/alphafold/">AlphaFold blog post</a> - AlphaFold, Google DeepMind&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p><a href="https://towardsdatascience.com/temporal-graph-networks-ab8f327f2efe">Temporal Graphs at Twitter</a> - Temporal Graph Networks, Bronstein and Emanuele Rossi medium post&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Gori, M., Monfardini, G., &amp; Scarselli, F. (2005). A new model for learning in graph domains. Proceedings IEEE IJCNN.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., &amp; Monfardini, G. (2009). The graph neural network model. IEEE transactions on neural networks, 20(1), 61-80.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Haralick, R. M. (1994). Document image understanding: Geometric and logical layout. CVPR &lsquo;94.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Nagy, G., &amp; Seth, S. (1984). Hierarchical representation of optically scanned documents. ICPR.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Kise, K., Sato, A., &amp; Iwata, M. (1998). Segmentation of page images using the area Voronoi diagram. Computer Vision and Image Understanding.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Gemelli, A., Biswas, S., Civitelli, E., Llad√≥s, J., &amp; Marinai, S. (2022). Doc2Graph: A Task Agnostic Document Understanding Framework Based on Graph Neural Networks. In Computer Vision ‚Äì ECCV 2022 Workshops (pp. 329-344).&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/docai/">DocAI</a></li>
      <li><a href="http://localhost:1313/tags/graphs/">Graphs</a></li>
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How Documents Met Graph Theory on x"
            href="https://x.com/intent/tweet/?text=How%20Documents%20Met%20Graph%20Theory&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocs_and_graphs%2f&amp;hashtags=DocAI%2cGraphs">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How Documents Met Graph Theory on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocs_and_graphs%2f&amp;title=How%20Documents%20Met%20Graph%20Theory&amp;summary=How%20Documents%20Met%20Graph%20Theory&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocs_and_graphs%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
</ul>

  </footer><script src="https://giscus.app/client.js"
        data-repo="andreagemelli/andreagemelli.github.io"
        data-repo-id="R_kgDOH26OFQ"
        data-category="Q&A"
        data-category-id="DIC_kwDOH26OFc4CkUt5"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Andrea Gemelli</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
